{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING DATABASE: ./Rating_1.xlsx\n",
      "READING DATABASE: ./Rating_3.xlsx\n",
      "READING DATABASE: ./Rating_2.xlsx\n",
      "READING DATABASE: ./Rating_5.xlsx\n",
      "READING DATABASE: ./Rating_4.xlsx\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.DataFrame() \n",
    "    \n",
    "for filename in glob.glob(\"./Rating_*.xlsx\"):\n",
    "#    connres.commit()\n",
    "    print (\"READING DATABASE: \"+filename)\n",
    "    df = pd.read_excel(open(filename,'rb'), sheet_name=\"Resultados\",header = None) #Reading SABI Export without index  \n",
    "    df.columns = ['id', 'nombre_x', 'nif', 'nombre', 'provincia', 'calle', 'telefono', 'web', 'desc_actividad', 'cnae', 'cod_consolidacion', 'rating_grade_h2', 'rating_grade_h1', 'rating_grade_h0', 'rating_numerico_h2', 'rating_numerico_h1', 'rating_numerico_h0', 'modelo_propension_h2', 'modelo_propension_h1', 'modelo_propension_h0', 'guo_nombre', 'guo_id_bvd', 'guo_pais', 'guo_tipo', 'estado_detallado', 'fecha_cambio_estado', 'fecha_constitucion', 'p10000_h0', 'p10000_h1', 'p10000_h2', 'p20000_h0', 'p20000_h1', 'p20000_h2', 'p31200_h0', 'p31200_h1', 'p31200_h2', 'p32300_h0', 'p32300_h1', 'p32300_h2', 'p40100_mas_40500_h0', 'p40100_mas_40500_h1', 'p40100_mas_40500_h2', 'p40800_h0', 'p40800_h1', 'p40800_h2', 'p49100_h0', 'p49100_h1', 'p49100_h2']\n",
    "    df['h0_anio'] = 2017     \n",
    "    df = df.fillna('')\n",
    "    df=df.drop(df.index[0]) #Dropping SABI variable names.\n",
    "    df['nif'] = df.nif.str.upper() #CONVERTING cif INTO UPPERCASE\n",
    "    for partida in ['p10000_h0', 'p10000_h1', 'p10000_h2', 'p20000_h0', 'p20000_h1', 'p20000_h2', 'p31200_h0', 'p31200_h1', 'p31200_h2', 'p32300_h0', 'p32300_h1', 'p32300_h2', 'p40100_mas_40500_h0', 'p40100_mas_40500_h1', 'p40100_mas_40500_h2', 'p40800_h0', 'p40800_h1', 'p40800_h2', 'p49100_h0', 'p49100_h1', 'p49100_h2']:\n",
    "#        print (partida,\"ha sido convertido en numerico\")\n",
    "        df[partida] = pd.to_numeric(df[partida], errors='coerce').fillna(0)- 0.005\n",
    "    df['nif_normalizado'] = df['nif'].str[-8:]    \n",
    "    big_df = big_df.append(df, ignore_index=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = big_df\n",
    "df['target_status'] = [0 if i in ['Activa', ''] else 1 for i in df['estado_detallado']] # 0 si Activa, 1 si algo raro!\n",
    "\n",
    "# _h0, _h1, _h2\n",
    "# _h0: history 0, here h0 means the year 2017 (historia 0, aquí h0 significa el año 2017)\n",
    "# _h1: history -1, here h1 means the year 2016 (historia -1, aquí h1 significa el año 2016)\n",
    "# _h2: history -2, here h2 means the year 2015 (historia -2, aquí h2 significa el año 2015)\n",
    "\n",
    "# Ebita Margin - Ebitda / Turn over (Ventas)\n",
    "# p49100: Profit (Resultado del ejercicio)\n",
    "# p40800: Amortization (Amortización) \n",
    "# p40100: Sales Turnover (Ingresos de Explotación)\n",
    "# p40500: Other sales (Otros Ingresos)\n",
    "df['ebitda_income'] = (df.p49100_h1+df.p40800_h1)/(df.p40100_mas_40500_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ocon/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/ocon/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Total Debt / Ebita \n",
    "# p31200: Short Term Debt / Deuda a corto plazo\n",
    "# p32300: Long Term Debt / Deuda a largo plazo\n",
    "# p49100: Profit (Resultado del ejercicio)\n",
    "# p40800: Amortization (Amortización) \n",
    "df['debt_ebitda'] =(df.p31200_h1 + df.p32300_h1) /(df.p49100_h1+df.p40800_h1) \n",
    "\n",
    "# rraa_rrpp: Financial leveraging / apalancamiento financiero \n",
    "# p10000: Total Assets / Total activos\n",
    "# p20000: Own Capital / Patrimonio neto\n",
    "df['rraa_rrpp'] = (df.p10000_h1 - df.p20000_h1) /df.p20000_h1\n",
    "\n",
    "# Log of Operating Income\n",
    "df['log_operating_income'] = np.log(df.p40100_mas_40500_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[['cnae','ebitda_income','debt_ebitda','rraa_rrpp','log_operating_income','target_status']].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X = df_clean[['cnae', 'ebitda_income','debt_ebitda','rraa_rrpp','log_operating_income']]\n",
    "y = df_clean['target_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categrical features to pass down the categorical pipeline \n",
    "categorical_features = [\"cnae\"]\n",
    "\n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numerical_features = ['ebitda_income','debt_ebitda','rraa_rrpp','log_operating_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNAE_Transformer(BaseEstimator, TransformerMixin ):   \n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):  \n",
    "        X = X.copy()\n",
    "        X.loc[:, \"sector\"] = X.cnae.str[:2]\n",
    "        X.sector = X.sector.str.strip()\n",
    "        X = X.replace({\"sector\":\"\"}, \"missing\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mean_Imputer(BaseEstimator, TransformerMixin ):   \n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        return self\n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):  \n",
    "        numeric_column_names = X.select_dtypes(include =[\"float64\", \"int\"]).columns\n",
    "        X = X.copy()\n",
    "        X[numeric_column_names] = X[numeric_column_names].fillna(X.mean())\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GroupNormalizer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class used for imputing missing values in a pd.DataFrame using either mean or median of a group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    group_cols : list\n",
    "        List of columns used for calculating the aggregated value \n",
    "    target : str\n",
    "        The name of the column to impute\n",
    "    metric : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : array-like\n",
    "        The array with imputed values in the target column\n",
    "    '''\n",
    "    def __init__(self, group_cols, target):\n",
    "        \n",
    "        self.group_cols = group_cols\n",
    "        self.target = target\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        assert pd.isnull(X[self.group_cols]).any(axis=None) == False, 'There are missing values in group_cols'\n",
    "        \n",
    "        impute_map = X.groupby(self.group_cols)[self.target].agg([np.mean, np.std]) \\\n",
    "                                                            .reset_index(drop=False)\n",
    "        \n",
    "        self.impute_map_ = impute_map.fillna(impute_map.median())\n",
    "        \n",
    "        return self \n",
    "    \n",
    "    def normalizer(self, df, group):\n",
    "        df[self.target]\n",
    "        \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # make sure that the imputer was fitted\n",
    "        check_is_fitted(self, 'impute_map_')\n",
    "        \n",
    "        X = X.copy()\n",
    "        df_final = pd.DataFrame(columns = X.columns)\n",
    "        for group, df in X.groupby(\"sector\"):\n",
    "            df_final = df_final.append(self.normalizer(df, group))\n",
    "            \n",
    "        \n",
    "        return self.impute_map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Pipeline([(\"CNAE_Transformer\", CNAE_Transformer()), (\"Mean_Imputer\", Mean_Imputer()), (\"standarize\", GroupNormalizer([\"sector\"], numeric_column_names))])\n",
    "Z = pp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí borrador son borradores y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standarizer( BaseEstimator, TransformerMixin ):   \n",
    "\n",
    "    #Return self nothing else to do here\n",
    "    def fit( self, X, y = None  ):\n",
    "        self.statistics_group = dict()\n",
    "        self.statistics_total = dict()\n",
    "        self.numeric_column_names = X.select_dtypes(include =[\"float64\", \"int\"]).columns\n",
    "        for group, df in X.groupby(\"sector\"):\n",
    "            self.statistics_group[group] = {\n",
    "                                \"mean\":{cn: df[cn].mean() for cn in self.numeric_column_names},\n",
    "                                \"std\": {cn: df[cn].std() for cn in self.numeric_column_names}                        \n",
    "                                }\n",
    "\n",
    "        self.statistics_total = { \"mean\":{cn: df[cn].mean() for cn in self.numeric_column_names},\n",
    "                             \"std\": {cn: df[cn].std() for cn in self.numeric_column_names}                        \n",
    "                            }       \n",
    "        return self\n",
    "\n",
    "    def normalize(self, x, group):\n",
    "        value_normalized = (x - self.statistics_group[group][\"mean\"]) / (self.statistics_group[group][\"std\"])         \n",
    "        return value_normalized\n",
    "        \n",
    "    \n",
    "    #Transformer method we wrote for this transformer \n",
    "    def transform(self, X , y = None ):      \n",
    "        X.apply(lambda x: self.normalize(X[self.numeric_column_names],X[\"sector\"]), axis = 1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
